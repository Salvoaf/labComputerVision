{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salvoaf/labComputerVision/blob/main/1_Text_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11u7hQr4BXfX"
      },
      "source": [
        "# Text preprocessing\n",
        "\n",
        "In this exercise, you'll need to implement basic text preprocessing steps."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SDoew83Gs2n",
        "outputId": "968e9e6c-20ad-4bcc-9dc9-6cdb33bfdc4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipytest\n",
            "  Downloading ipytest-0.12.0-py3-none-any.whl (15 kB)\n",
            "Collecting pytest>=5.4\n",
            "  Downloading pytest-7.1.3-py3-none-any.whl (298 kB)\n",
            "\u001b[K     |████████████████████████████████| 298 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipytest) (7.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ipytest) (21.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (22.1.0)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (2.0.1)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (1.11.0)\n",
            "Collecting iniconfig\n",
            "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (5.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (3.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 19.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (57.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->ipytest) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipytest) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipytest) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->ipytest) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipytest) (0.7.0)\n",
            "Installing collected packages: pluggy, jedi, iniconfig, pytest, ipytest\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed iniconfig-1.1.1 ipytest-0.12.0 jedi-0.18.1 pluggy-1.0.0 pytest-7.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UdhAkid9BXfZ"
      },
      "outputs": [],
      "source": [
        "from typing import List, Set\n",
        "\n",
        "import ipytest\n",
        "import string\n",
        "import re\n",
        "\n",
        "ipytest.autoconfig()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBMNue1xBXfb"
      },
      "source": [
        "## Task 1: Tokenization\n",
        "\n",
        "Split an input text into tokens based on whitespaces, punctuation, hyphens, and HTML markup. Additionally, lowercase all tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sixLiI6IBXfc"
      },
      "outputs": [],
      "source": [
        "from IPython.core.interactiveshell import Type\n",
        "def tokenize(text: str)-> List[str]:   \n",
        "    \"\"\"Returns a sequence of terms given an input text.\"\"\"\n",
        "    text= text.lower()\n",
        "    punt = \"\\\\s+|\\<.*?>\"\n",
        "    for i in string.punctuation:\n",
        "      if i == \"<\" or i == \">\":\n",
        "        continue\n",
        "      punt = punt +\"|\\\\\" +i+ \"+\"\n",
        "    PATTERN = r''+punt\n",
        "    resu = re.split(PATTERN, text)\n",
        "    resu = list(filter(lambda a: a != '', resu))\n",
        "    return resu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdgzsU7QBXfc"
      },
      "source": [
        "Tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs-3p1edBXfd",
        "outputId": "ec9c0411-79cd-4a8d-985e-b938b99e0a6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                         [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%%ipytest\n",
        "\n",
        "def test_whitespace():\n",
        "    assert tokenize(\"aaa bbb ccc\") == [\"aaa\", \"bbb\", \"ccc\"]\n",
        "    \n",
        "def test_punctuation():\n",
        "    assert tokenize(\"aaa! bbb.ccc,ddd:eee ff\\\"f\") == [\"aaa\", \"bbb\", \"ccc\", \"ddd\", \"eee\", \"ff\", \"f\"]\n",
        "    \n",
        "def test_hyphens():\n",
        "    assert tokenize(\"aaa bbb-Ccc\") == [\"aaa\", \"bbb\", \"ccc\"]\n",
        "    \n",
        "def test_html():\n",
        "    assert tokenize(\"aaa <bbb>ccc <ddd>eee</ddd></bbb>fff <ggg />\") == [\"aaa\", \"ccc\", \"eee\", \"fff\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wLbxG-RBXfd"
      },
      "source": [
        "## Task 2: Stopwords removal\n",
        "\n",
        "Remove stopwords from a sequence of tokens, given a set of stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXYIf1TqBXfe"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(tokens: List[str], stopwords: Set[str]) -> List[str]:\n",
        "    \"\"\"Removes stopwords from a sequence of tokens.\"\"\"\n",
        "    tokens_without_sw = [word for word in tokens if not word in stopwords]\n",
        "    return tokens_without_sw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoD7in-nBXff"
      },
      "source": [
        "Tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajxBfmI7BXfg",
        "outputId": "307da701-f41d-4b7e-aa73-e17e8eb961e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                          [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%%ipytest\n",
        "\n",
        "def test_no_stopwords():\n",
        "    assert remove_stopwords([\"this\", \"is\", \"some\", \"text\"], {}) == [\"this\", \"is\", \"some\", \"text\"]\n",
        "    \n",
        "def test_stopwords():\n",
        "    assert remove_stopwords([\"this\", \"is\", \"some\", \"text\"], {\"is\", \"this\"}) == [\"some\", \"text\"]\n",
        "    \n",
        "def test_stopwords2():\n",
        "    assert remove_stopwords([\"this\", \"isolate\", \"otto\"], {\"is\", \"this\", \"to\"}) == [\"isolate\", \"otto\"]    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rxLCw_xBXfg"
      },
      "source": [
        "## Task 3: Suffix-s stemming\n",
        "\n",
        "Remove the s-suffix from all terms in a sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg1V6CJRBXfh"
      },
      "outputs": [],
      "source": [
        "def suffix_s_stemmer(terms: List[str]) -> List[str]:\n",
        "    \"\"\"Removes the s-suffix from all terms in a sequence.\"\"\"\n",
        "    resu = []\n",
        "    PATTERN = \"[sS]\"\n",
        "    for i in terms:\n",
        "      resu.append(re.split(PATTERN, i)[0])\n",
        "    print(resu)\n",
        "    return resu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtIgeTNpBXfh"
      },
      "source": [
        "Tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qY1JuYTBXfh",
        "outputId": "5650a5e5-3245-43c1-8716-2620a991c77d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%%ipytest\n",
        "\n",
        "def test_stemming():\n",
        "    assert suffix_s_stemmer([\"dogs\", \"better\", \"cats\"]) == [\"dog\", \"better\", \"cat\"]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 ('mircv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "6c5e4a7eaa80b8b0cab0ebfd023b62b4fb81ced96acf97d50ef5e35c1384dc27"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}