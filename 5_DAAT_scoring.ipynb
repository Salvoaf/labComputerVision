{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salvoaf/labComputerVision/blob/main/5_DAAT_scoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDfg0WdPFSeT"
      },
      "source": [
        "# Document-at-a-time Query Processing\n",
        "\n",
        "Implement document-at-a-time query processing using a simple scoring function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEVA0TCsFUmx",
        "outputId": "9ba38088-1248-4b1c-8f5d-2af7724b41db"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipytest in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ipytest) (21.3)\n",
            "Requirement already satisfied: pytest>=5.4 in /usr/local/lib/python3.7/dist-packages (from ipytest) (7.1.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipytest) (7.9.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (1.0.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (1.1.1)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (1.11.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (2.0.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (22.1.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (3.9.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.18.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (57.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->ipytest) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipytest) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipytest) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->ipytest) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipytest) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "collapsed": true,
        "id": "JmJYO8NHFSeU"
      },
      "outputs": [],
      "source": [
        "import ipytest\n",
        "import pytest\n",
        "\n",
        "from typing import Dict, List, Tuple\n",
        "from collections import Counter\n",
        "\n",
        "ipytest.autoconfig()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6puCPXadFSeV"
      },
      "source": [
        "### Inverted index\n",
        "\n",
        "For simplicity, the inverted index for the document collection is given as a dictionary, with a terms as keys and posting lists as values. Each posting is a (document ID, term frequency) tuple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "collapsed": true,
        "id": "ANhBjabeFSeV"
      },
      "outputs": [],
      "source": [
        "\"beijing duck recipe\"\n",
        "index = {\n",
        "    \"beijing\": [        (1, 1),                 (4, 1)],\n",
        "    \"dish\":    [        (1, 1),                 (4, 1)],\n",
        "    \"duck\":    [(0, 3), (1, 2), (2, 2),         (4, 1)],\n",
        "    \"rabbit\":  [                (2, 1), (3, 1)        ],\n",
        "    \"recipe\":  [                (2, 1), (3, 1), (4, 1)]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B833B8cFSeW"
      },
      "source": [
        "### Document lengths\n",
        "\n",
        "The length of each document is provided in a list (Normally, this information would be present in a document index).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "collapsed": true,
        "id": "b6NF7vG8FSeW"
      },
      "outputs": [],
      "source": [
        "doc_len = [3, 4, 4, 2, 4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtF0gm4rFSeW"
      },
      "source": [
        "### Document-at-a-time scoring\n",
        "\n",
        "The retrieval function we use is the following:\n",
        "\n",
        "$$score(q,d) = \\sum_{t \\in q} w_{t,d} \\times w_{t,q}$$\n",
        "\n",
        "where $w_{t,d}$ and $w_{t,q}$ are length-normalized term frequencies, i.e., $w_{t,d} = \\frac{c_{t,d}}{|d|}$, where $c_{t,d}$ is the number of occurrences of term $t$ in document $d$ and $|d|$ is the document length, i.e., the total number of terms. Similarly for the query.\n",
        "\n",
        "We utilize the fact that the posting lists are ordered by document ID. Then, it's enough to iterate in parallel through term query term's posting list, and score the minimum docid at each iteration. We keep a pointer for each query term and we move it forward every time a docid is scored.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FL_BqC1FSeW"
      },
      "source": [
        "We use an helper function that, given a dict of posting list pointers `pos`, returns the minimum docid. If all pointers go beyond the end of the corresponding posting list, we return `num_docs`, a special docid that it is guaranteed to not appear in any posting list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "DFTR0eeZFSeX"
      },
      "outputs": [],
      "source": [
        "def min_docid(index: Dict[str, List[Tuple[int, int]]], \n",
        "              pos: Dict[str, int],\n",
        "              num_docs: int, actualdocid) -> int:\n",
        "    \"\"\"Returns the minimum docid across posting lists.\n",
        "    \n",
        "    Args:\n",
        "        index: Dict holding the inverted index.\n",
        "        pos: the current positions in the query posting lists.\n",
        "        num_docs: the number of indexed documents.\n",
        "    \n",
        "    Returns:\n",
        "        the minimum docid across the posting lists, or num_docs if all \n",
        "        postings in all posting lists have been processed.\n",
        "    \"\"\"\n",
        "    min_docid = num_docs\n",
        "    # For each query term posting list.\n",
        "    for term, pointer in index.items():\n",
        "      for docid in pointer:\n",
        "          if docid[0] < min_docid and docid[0] > actualdocid:\n",
        "            min_docid = docid[0]  \n",
        "\n",
        "         # TODO: check if the posting list contains a valid docid; if so, update min_docid\n",
        "        \n",
        "    # Return the min docid computed.\n",
        "   \n",
        "    return min_docid"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLAvERtVHq1m",
        "outputId": "a01fdcd9-7960-4cc6-c8d4-783a36576bbf"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 1), (4, 1)]\n",
            "[(1, 1), (4, 1)]\n",
            "[(0, 3), (1, 2), (2, 2), (4, 1)]\n",
            "[(2, 1), (3, 1)]\n",
            "[(2, 1), (3, 1), (4, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "HGSpVYRhFSeX"
      },
      "outputs": [],
      "source": [
        "def score_collection(index: Dict[str, List[Tuple[int, int]]], \n",
        "                      doc_len: List[int], \n",
        "                      query: str) -> List[Tuple[int, float]]:\n",
        "    \"\"\"Scores all documents in the collection.\n",
        "    \n",
        "    Args:\n",
        "        index: Dict holding the inverted index.\n",
        "        doc_len: List with document lengths.\n",
        "        query: Search query.\n",
        "    \n",
        "    Returns:\n",
        "        List with (document_id, score) tuples, ordered by score desc.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Turns the query string into a \"term: freq\" dictionary.\n",
        "    query_freqs = dict(Counter(query.split()))\n",
        "\n",
        "    # Computes query length (i.e., sum of all query term frequencies).\n",
        "    query_len = sum(query_freqs.values())\n",
        "\n",
        "    doc_scores = {}  # Holds the final document scores (this should be a priority list, but for simplicity we use a dictionary here).\n",
        "    \n",
        "    pos = {term: 0 for term in query_freqs}  # Holds a pointer for each query term's posting list.\n",
        "    \n",
        "    # The starting docid.\n",
        "    docid = min_docid(index, pos, len(doc_len),-1)\n",
        "    # While the posting lists have not been completely traversed.\n",
        "    vector_docid =[]\n",
        "    doc_score = []\n",
        "    position = 0\n",
        "    matrix_index = []\n",
        "    while docid != len(doc_len):\n",
        "        vector_docid.append(docid)\n",
        "        score = 0.0\n",
        "        scalar_list_index = []\n",
        "        \n",
        "        mod_d = 0\n",
        "        \n",
        "        for term, postlisting in index.items():\n",
        "          score = 0.0\n",
        "          for id, frq in postlisting:\n",
        "            if id == docid:\n",
        "              c = frq\n",
        "              mod_d = doc_len[position]\n",
        "              score = c/mod_d\n",
        "          scalar_list_index.append(score)\n",
        "          \n",
        "        matrix_index.append(scalar_list_index)\n",
        "\n",
        "        \n",
        "        scalar_list_query = []\n",
        "        for term, freq_query in index.items():\n",
        "          if term in query_freqs.keys():\n",
        "            cq = query_freqs[term]  #ricorrenza della parola in quella query\n",
        "            mod_q = len(query_freqs) #lunghezza query\n",
        "            score = cq/mod_q\n",
        "            scalar_list_query.append(score)\n",
        "          else:\n",
        "            scalar_list_query.append(0.0)\n",
        "        \n",
        "\n",
        "        \n",
        "        # Update the docid.\n",
        "         \n",
        "        docid = min_docid(index, pos, len(doc_len),docid)\n",
        "        position = position +1\n",
        "    for j, vector in enumerate(matrix_index):\n",
        "      val = 0.0\n",
        "      \n",
        "      for i, elem in enumerate(vector):\n",
        "        val = val + scalar_list_query[i]*elem\n",
        "        \n",
        "      doc_score.append([j,val])\n",
        "    # TODO: return doc_scores sorted\n",
        "    \n",
        "\n",
        "    if doc_score != []:\n",
        "      return doc_score\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cft8a9p0FSeY"
      },
      "source": [
        "#### Tests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = score_collection(index, doc_len, \"beijing duck recipe\") \n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xibQw_BtCyi1",
        "outputId": "83d1433a-28ce-4806-c9b7-268984f7e21b"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0.3333333333333333],\n",
              " [1, 0.25],\n",
              " [2, 0.25],\n",
              " [3, 0.16666666666666666],\n",
              " [4, 0.25]]"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPGwqJe7FSeY",
        "outputId": "97b8fac2-42ab-4a59-cbe1-fa8d501acf7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%%ipytest\n",
        "\n",
        "def test_scoring():\n",
        "    scores = score_collection(index, doc_len, \"beijing duck recipe \")    \n",
        "    assert scores[0][0] == 0\n",
        "    assert scores[0][1] == pytest.approx(1/3, rel=1e-2)\n",
        "    assert scores[2][0] == 2\n",
        "    assert scores[2][1] == pytest.approx(1/4, rel=1e-2)\n",
        "    assert scores[3][0] == 3\n",
        "    assert scores[3][1] == pytest.approx(1/6, rel=1e-2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "podaaIsDFSeZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 ('mircv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "6c5e4a7eaa80b8b0cab0ebfd023b62b4fb81ced96acf97d50ef5e35c1384dc27"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}